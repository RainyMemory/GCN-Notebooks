{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":["import torch\n","print(torch.__version__)\n","print(torch.version.cuda)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["!pip install --no-index torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cpu.html\n","!pip install --no-index torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cpu.html\n","!pip install --no-index torch-cluster -f https://pytorch-geometric.com/whl/torch-1.7.0+cpu.html\n","!pip install --no-index torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.7.0+cpu.html\n","!pip install torch-geometric"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["from torch_geometric.data import Data\n","\n","# data.edge_index: Graph connectivity in COO format with shape [2, num_edges] and type torch.long\n","# if in shape [num_edges, 2]: using edge_index.t().contiguous() to transform the tensor\n","edge_index = torch.tensor([[0, 1, 1, 2],[1, 0, 2, 1]], dtype=torch.long)\n","# data.x: Node feature matrix with shape [num_nodes, num_node_features]\n","# all the nodes here only have 1 feature.\n","x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n","# data.edge_attr: Edge feature matrix with shape [num_edges, num_edge_features]\n","# data.pos: Node position matrix with shape [num_nodes, num_dimensions]\n","# the features for nodes and edges are kept separately\n","# None of these attributes is required, for example, when edges are not provided with attributes, edge_attr is None\n","# create a graph with defined nodes and edges\n","data = Data(x=x, edge_index=edge_index)\n","\n","# some attributes about the graph\n","print(\"Keys in the graph dict:\", data.keys)\n","print(\"Feature num for each node:\", data.num_node_features)\n","print(\"The num of nodes:\", data.num_nodes)\n","print(\"The num of edges\", data.num_edges)\n","# pre-built functions\n","print(\"Isolation:\", data.contains_isolated_nodes())\n","print(\"Self loop:\", data.contains_self_loops())\n","print(\"Is directed:\", data.is_directed())"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["from torch_geometric.datasets import TUDataset\n","\n","# load the ENZYMES sample dataset\n","dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n","print(\"Graph num:\", len(dataset))\n","print(\"Class num:\", dataset.num_classes)\n","print(\"Feature num for each node:\", dataset.num_node_features)\n","# select one graph after shuffling\n","data = dataset.shuffle()[-1]\n","print(\"Is directed:\", data.is_directed())\n","print(\"Graph info:\", data)\n","# the shape of y(target) is [1], so ENZYMES dataset can be used for graph classification(embedding) traing: graph-level"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["from torch_geometric.datasets import Planetoid\n","\n","# load the Cora dataset: node-level\n","dataset = Planetoid(root='/tmp/Cora', name='Cora')\n","print(\"Graph num:\", len(dataset))\n","print(\"Class num:\", dataset.num_classes)\n","print(\"Feature num for each node:\", dataset.num_node_features)\n","data = dataset[0]\n","print(\"Graph info:\", data)\n","# it's a single, undirected citation graph\n","print(\"The num of masked items in training set:\", data.train_mask.sum().item())"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv\n","\n","# build a small GCN for node classification\n","class NodeClsNet(torch.nn.Module):\n","    def __init__(self, dataset, hidden_dim):\n","        super(NodeClsNet, self).__init__()\n","        # two GCN conv layers\n","        self.conv1 = GCNConv(dataset.num_node_features, hidden_dim)\n","        self.conv2 = GCNConv(hidden_dim, dataset.num_classes)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        # propagating\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        # output logits\n","        return F.log_softmax(x, dim=1)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# prepare the model\n","model = NodeClsNet(dataset, 32).to(device)\n","data = dataset.shuffle()[-1].to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","model.train()\n","# try to train the model\n","for epoch in range(200):\n","    out = model(data)\n","    # the -LL loss\n","    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n","    optimizer.zero_grad()\n","    # backpropagation\n","    loss.backward()\n","    optimizer.step()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["model.eval()\n","_, pred = model(data).max(dim=1)\n","# correct the num of right classified samples\n","correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n","acc = correct / int(data.test_mask.sum())\n","print('Accuracy: {:.4f}'.format(acc))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Generalizing the convolution operator to irregular domains is typically expressed as a neighborhood aggregation or message passing scheme.\n","# how to define the neighbourhoods and how to aggregate data from them are the most important qestions when designing GCNs\n","# the choosen of aggregation mehtods and neighbourhoods reflect the basis you are try to applying, like the Laplacian or wavlet basis\n","from torch_geometric.nn import MessagePassing\n","from torch_geometric.utils import add_self_loops, degree\n","\n","# implement an GCN conv layer\n","# neighboring node features are first transformed by a weight matrix Θ, normalized by their degree, and finally, aggregation\n","class CustomGCNConv(MessagePassing):\n","    def __init__(self, in_channels, out_channels):\n","        # i.e. aggr=\"add\", aggr=\"mean\" or aggr=\"max\".\n","        super(CustomGCNConv, self).__init__(aggr='add') \n","        # the layers to adjust the neighbours' embeddings before aggregation\n","        self.lin = torch.nn.Linear(in_channels, out_channels)\n","        \n","    def forward(self, x, edge_index):\n","        # Step 1: Add self-loops to the adjacency matrix (nodes can reach themselves)\n","        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n","        # Step 2: Linearly transform node feature matrix.\n","        x = self.lin(x)\n","        # Step 3: Compute normalization.\n","        row, col = edge_index\n","        # the D matrix: degree of each node, this process can be put into the message function\n","        deg = degree(col, x.size(0), dtype=x.dtype)\n","        # The normalization coefficients are derived by the node degrees deg(i) for each node i which gets transformed to 1/(deg(i)^(1/2)⋅deg(j)^(1/2)) for each edge (j,i)∈E.\n","        deg_inv_sqrt = deg.pow(-0.5)\n","        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n","        # Step 4-5: Start propagating messages, this will activate the message function automatically\n","        # x has the adjusted embeddings of neighbours and norm is calculated for normalisation\n","        return self.propagate(edge_index, x=x, norm=norm)\n","\n","    def message(self, x_j, norm):\n","        # Step 4: Normalize node features.\n","        # normalise each node: point-wise fashion\n","        return norm.view(-1, 1) * x_j"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Implementing the Edge Convolution\n","class CustomEdgeConv(MessagePassing):\n","    def __init__(self, in_channels, out_channels):\n","        super(CustomEdgeConv, self).__init__(aggr='max')\n","        self.mlp = torch.nn.Sequential(\n","            torch.nn.Linear(2 * in_channels, out_channels),\n","            torch.nn.ReLU(),\n","            torch.nn.Linear(out_channels, out_channels)\n","        )\n","\n","    def forward(self, x, edge_index):\n","        # not adjust the attributes of edges\n","        return self.propagate(edge_index, x=x)\n","\n","    def message(self, x_i, x_j):\n","        # concate extra info to the target edge\n","        tmp = torch.cat([x_i, x_j - x_i], dim=1)  # tmp has shape [E, 2 * in_channels]\n","        return self.mlp(tmp)\n","    \n","from torch_geometric.nn import knn_graph\n","\n","# edge convolution is actually a dynamic convolution, which recomputes the graph for each layer using nearest neighbors in the feature space\n","# edge convolution should be useful when doing the graph-level job: summarize the info of subgraphs\n","class DynamicEdgeConv(CustomEdgeConv):\n","    def __init__(self, in_channels, out_channels, k=6):\n","        super(DynamicEdgeConv, self).__init__(in_channels, out_channels)\n","        self.k = k\n","\n","    def forward(self, x, batch=None):\n","        # torch_geometric.nn.pool.knn_graph(): a GPU accelerated batch-wise k-NN graph generation method \n","        edge_index = knn_graph(x, self.k, batch, loop=False, flow=self.flow)\n","        return super(DynamicEdgeConv, self).forward(x, edge_index)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["import os.path as osp\n","from torch_geometric.data import Dataset\n","\n","# create a customized dataset\n","class MyOwnDataset(Dataset):\n","    # the pre_transform function can: split the graph into subgraphs with knn method or etc.\n","    # once defined the pre_transform function and save the data, it will automatically do the pre_transform when loaded again.\n","    def __init__(self, root, transform=None, pre_transform=None):\n","        super(MyOwnDataset, self).__init__(root, transform, pre_transform)\n","\n","    @property\n","    def raw_file_names(self):\n","        # may split the training files into serval parts\n","        return ['some_file_1', 'some_file_2', ...]\n","\n","    @property\n","    def processed_file_names(self):\n","        # data after transform/process\n","        return ['data_1.pt', 'data_2.pt', ...]\n","\n","    # You can skip downloading and/or processing by just not overriding the download() and process() methods\n","    def download(self):\n","        # Download to `self.raw_dir`.\n","\n","    def process(self):\n","        i = 0\n","        for raw_path in self.raw_paths:\n","            # Read data from `raw_path`.\n","            data = Data(...)\n","            if self.pre_filter is not None and not self.pre_filter(data):\n","                continue\n","            if self.pre_transform is not None:\n","                data = self.pre_transform(data)\n","            torch.save(data, osp.join(self.processed_dir, 'data_{}.pt'.format(i)))\n","            i += 1\n","\n","    def len(self):\n","        return len(self.processed_file_names)\n","\n","    def get(self, idx):\n","        data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(idx)))\n","        return data"],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}